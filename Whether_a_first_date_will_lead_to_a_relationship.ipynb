{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMtR7uYWze49"
      },
      "source": [
        "# Answering the questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olwanI3xzgol"
      },
      "source": [
        "âœ”ï¸ Answer the questions below (briefly):\n",
        "\n",
        "ðŸŒˆ Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n",
        "\n",
        "- because linear regression is usually used to predict continuous values but classification is used to predict discrete values, and linear regression is senstive to outliers.\n",
        "\n",
        "- logistic regression is usually used for classification task and A perceptron's used as binary classifier like logistic regression but the difference is that perceptron uses step activation function.\n",
        "\n",
        "- both logistic regression and preceptron are better than linear regression in classification task.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ðŸŒˆWhat's a decision tree and how it is different to a logistic regression model?\n",
        "\n",
        "- A decision tree is a supervised machine learning that categorizes or predicts outcomes based on the answers to a previous set of questions.\n",
        "\n",
        "- It has a tree-like structure with branches and nodes that represent different outcomes or decisions.\n",
        "\n",
        "**The difference between decision tree and logistic regression is that:** \n",
        "- logistic regression assumes that the data is linearly separable in space.\n",
        "\n",
        "- decision tree is a non-linear classifier.\n",
        "\n",
        "- Decision trees can handle categorical data better, while logistic regression can handle continuous data better.\n",
        "\n",
        "\n",
        "ðŸŒˆWhat's the difference between grid search and random search?\n",
        "\n",
        "- Grid search tries every possible hyperparameter combination to find the best one, but it is very slow to run.\n",
        "\n",
        "- Random search randomly picks hyperparameter combinations from a grid and evaluates the model performance. It is faster than grid search, but it may not find the optimal hyperparameters.\n",
        "\n",
        "ðŸŒˆWhat's the difference between bayesian search and random search?\n",
        "\n",
        "- Bayesian search is an optimization algorithm that sequentially uses a model-based approach to determine the next hyperparameter value based on the results of the previous iteration.\n",
        "\n",
        "- Random search uses a grid of hyperparameter values and selects random combinations for training and scoring the model.\n",
        "\n",
        "- In terms of finding the best hyperparameters, Bayesian search outperforms random search and is faster than grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnm8UOnNGEb9"
      },
      "source": [
        "# Problem Formulation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhamrdTnF14O"
      },
      "source": [
        "## Problem description\n",
        "\n",
        "- building a machine learning model to predict the probability (0-1, float) output that the dating will match. \n",
        "\n",
        "- inputs : (191 features) for both training set (5909 observations) and (9842 observations) after the oversampling and test set (2469 observations) \n",
        "\n",
        "- output : 1 feature 2469 observations as output (Using Test Data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYyanQEGGJmV"
      },
      "source": [
        "## Model\n",
        "- classification and prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lFGPq3bGMbH"
      },
      "source": [
        "## Challenges\n",
        "\n",
        "- that our dataset has a lot of null values \n",
        "\n",
        "- that the is an imbalanced dataset a lot 0's and less of 1's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z5TkHsQGMeO"
      },
      "source": [
        "\n",
        "## Model impact\n",
        "\n",
        "- It help people to meet their suitable partners "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BClkdXwdGMhF"
      },
      "source": [
        "\n",
        "## The ideal solution\n",
        "\n",
        "- Using a XGBClassifierr with random search to search for the best hyperparameters combinations to get better ROC-AUC result on the test data is (88.835%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlxVAhaT13MO"
      },
      "source": [
        "# Importing Libraries and check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc5RJDBr2bFF",
        "outputId": "53a5f104-4316-4fe5-b1d2-122b231144ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-optimize) (1.21.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9tjO7WkFzph",
        "outputId": "5a94be00-e733-47ae-ced8-a199f550c66c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from imbalanced-learn) (1.21.2)\n",
            "Installing collected packages: joblib, imbalanced-learn\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "Successfully installed imbalanced-learn-0.10.1 joblib-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-NlWCTRFzpi",
        "outputId": "5b0678a1-db0e-4d60-fe32-ca68f6106297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-1.7.4-py3-none-win_amd64.whl (89.1 MB)\n",
            "Requirement already satisfied: numpy in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from xgboost) (1.21.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\dekaito\\anaconda3\\envs\\py3-tf2.0\\lib\\site-packages (from xgboost) (1.7.3)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-1.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HWAkKhunMpJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn import metrics\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from pandas.core.arrays import numeric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skopt.space import Categorical ,Integer ,Real\n",
        "from sklearn.pipeline import Pipeline\n",
        "from pandas.core.arrays import numeric\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "29iCBwZZ2LEl",
        "outputId": "80ae7993-1d80-4094-c175-c04f0002f2b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>331.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5508</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4828</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 191 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "id                                                                           \n",
              "2583       0    3       2    14     18         2       2.0     14       12   \n",
              "6830       1   14       1     3     10         2       NaN      8        8   \n",
              "4840       1   14       1    13     10         8       8.0     10       10   \n",
              "5508       1   38       2     9     20        18      13.0      6        7   \n",
              "4828       1   24       2    14     20         6       6.0     20       17   \n",
              "\n",
              "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
              "id           ...                                                        \n",
              "2583  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "6830   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN   \n",
              "4840  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "5508  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN   \n",
              "4828  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "\n",
              "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
              "id                                       \n",
              "2583      NaN       NaN     NaN     NaN  \n",
              "6830      NaN       NaN     NaN     NaN  \n",
              "4840      NaN       NaN     NaN     NaN  \n",
              "5508      NaN       NaN     NaN     NaN  \n",
              "4828      NaN       NaN     NaN     NaN  \n",
              "\n",
              "[5 rows x 191 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load Data\n",
        "df_train= pd.read_csv(\"train.csv\", index_col='id')\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "np1fTsGD27OW",
        "outputId": "3abaf55a-6d93-485b-f67d-2faad3f9a371"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6757</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>212.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2275</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1052</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>162.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 190 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "id                                                                           \n",
              "934        0    5       2     2     16         3       NaN     13       13   \n",
              "6539       0   33       2    14     18         6       6.0      4        8   \n",
              "6757       1    6       2     9     20        10      16.0     15       19   \n",
              "2275       1   26       2     2     19        15       NaN      8       10   \n",
              "1052       0   29       2     7     16         7       7.0     10        5   \n",
              "\n",
              "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
              "id           ...                                                        \n",
              "934    52.0  ...      5.0      7.0       8.0     6.0     8.0      NaN   \n",
              "6539  368.0  ...      6.0      8.0       7.0     7.0     8.0      6.0   \n",
              "6757  212.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "2275   30.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "1052  162.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "\n",
              "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
              "id                                       \n",
              "934       NaN       NaN     NaN     NaN  \n",
              "6539      7.0       6.0     5.0     5.0  \n",
              "6757      NaN       NaN     NaN     NaN  \n",
              "2275      NaN       NaN     NaN     NaN  \n",
              "1052      NaN       NaN     NaN     NaN  \n",
              "\n",
              "[5 rows x 190 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test= pd.read_csv(\"test.csv\", index_col='id')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxEkMRP53ICd"
      },
      "source": [
        "**Check the Shape of the training and test Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPnyAXPq2-4t",
        "outputId": "e5d9e2af-4395-4528-c9f5-c39e249cdd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Date Shape:  (5909, 191)\n",
            "Testing Date Shape:  (2469, 190)\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Date Shape: \", df_train.shape)\n",
        "print(\"Testing Date Shape: \", df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QtJ0uOh5rie"
      },
      "source": [
        "# Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUNhzilr3WrW",
        "outputId": "18ccc264-123d-4279-bb57-12f4ae488730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "float64    173\n",
              "int64       10\n",
              "object       8\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9zXXfhY6D7s",
        "outputId": "4bd2a460-e246-42d2-f5b8-6c6f49fa5072"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "match\n",
              "0        4921\n",
              "1         988\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking the target Column\n",
        "df_train[['match']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "XDjj-_uB7Yos",
        "outputId": "5c4b720e-7520-46bf-f8db-d2a00e6761c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='count', ylabel='match'>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We Can See that the data is Imbalanced\n",
        "sns.countplot(y=\"match\", data=df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3_f2X4-6N4b",
        "outputId": "06423b31-976a-4c1f-f4a4-0f4f4361b24e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "304971"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Checking The Null values\n",
        "sum(df_train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EQmGHov6W9L",
        "outputId": "777f3e29-9bb2-43e5-e2a8-54d38fc00e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "127044"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(df_test.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Oh4_Pt8-6lO0",
        "outputId": "649d7ab3-741b-4eb5-eece-22e3118c7112"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>field</th>\n",
              "      <th>undergra</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>from</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>income</th>\n",
              "      <th>career</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>Ed.D. in higher education policy at TC</td>\n",
              "      <td>University of Michigan-Ann Arbor</td>\n",
              "      <td>1,290.00</td>\n",
              "      <td>21,645.00</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>University President</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>2,021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Engineer or iBanker or consultant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>Urban Planning</td>\n",
              "      <td>Rizvi College of Architecture, Bombay University</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bombay, India</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Real Estate Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5508</th>\n",
              "      <td>International Affairs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Washington, DC</td>\n",
              "      <td>10,471</td>\n",
              "      <td>45,300.00</td>\n",
              "      <td>public service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4828</th>\n",
              "      <td>Business</td>\n",
              "      <td>Harvard College</td>\n",
              "      <td>1,400.00</td>\n",
              "      <td>26,019.00</td>\n",
              "      <td>Midwest USA</td>\n",
              "      <td>66,208</td>\n",
              "      <td>46,138.00</td>\n",
              "      <td>undecided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3390</th>\n",
              "      <td>Clinical Psychology</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New York</td>\n",
              "      <td>11,803</td>\n",
              "      <td>65,708.00</td>\n",
              "      <td>Psychologist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4130</th>\n",
              "      <td>MBA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Colombia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1178</th>\n",
              "      <td>MA Science Education</td>\n",
              "      <td>University of Washington</td>\n",
              "      <td>1,155.00</td>\n",
              "      <td>13,258.00</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>98,115</td>\n",
              "      <td>37,881.00</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>Biochemistry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Canada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pharmaceuticals and biotechnology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8149</th>\n",
              "      <td>MFA Acting Program</td>\n",
              "      <td>Hamilton College</td>\n",
              "      <td>1,280.00</td>\n",
              "      <td>27,350.00</td>\n",
              "      <td>Cambridge, MA</td>\n",
              "      <td>2,140</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Actress</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       field  \\\n",
              "id                                             \n",
              "2583  Ed.D. in higher education policy at TC   \n",
              "6830                             Engineering   \n",
              "4840                          Urban Planning   \n",
              "5508                   International Affairs   \n",
              "4828                                Business   \n",
              "...                                      ...   \n",
              "3390                     Clinical Psychology   \n",
              "4130                                     MBA   \n",
              "1178                    MA Science Education   \n",
              "5016                            Biochemistry   \n",
              "8149                      MFA Acting Program   \n",
              "\n",
              "                                              undergra    mn_sat    tuition  \\\n",
              "id                                                                            \n",
              "2583                  University of Michigan-Ann Arbor  1,290.00  21,645.00   \n",
              "6830                                               NaN       NaN        NaN   \n",
              "4840  Rizvi College of Architecture, Bombay University       NaN        NaN   \n",
              "5508                                               NaN       NaN        NaN   \n",
              "4828                                   Harvard College  1,400.00  26,019.00   \n",
              "...                                                ...       ...        ...   \n",
              "3390                                               NaN       NaN        NaN   \n",
              "4130                                               NaN       NaN        NaN   \n",
              "1178                          University of Washington  1,155.00  13,258.00   \n",
              "5016                                               NaN       NaN        NaN   \n",
              "8149                                  Hamilton College  1,280.00  27,350.00   \n",
              "\n",
              "                from zipcode     income                             career  \n",
              "id                                                                          \n",
              "2583   Palo Alto, CA     NaN        NaN               University President  \n",
              "6830      Boston, MA   2,021        NaN  Engineer or iBanker or consultant  \n",
              "4840   Bombay, India     NaN        NaN             Real Estate Consulting  \n",
              "5508  Washington, DC  10,471  45,300.00                     public service  \n",
              "4828     Midwest USA  66,208  46,138.00                          undecided  \n",
              "...              ...     ...        ...                                ...  \n",
              "3390        New York  11,803  65,708.00                       Psychologist  \n",
              "4130        Colombia     NaN        NaN                         Consulting  \n",
              "1178         Seattle  98,115  37,881.00                            Teacher  \n",
              "5016          Canada     NaN        NaN  pharmaceuticals and biotechnology  \n",
              "8149   Cambridge, MA   2,140        NaN                            Actress  \n",
              "\n",
              "[5909 rows x 8 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.select_dtypes(include=['object'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5H4d30vjWwM"
      },
      "outputs": [],
      "source": [
        "# Remove string Column to convert it to Number\n",
        "df_train.mn_sat = df_train.mn_sat.str.replace((\",\"), (\"\"))\n",
        "df_train.income = df_train.income.str.replace((\",\"), (\"\"))\n",
        "\n",
        "df_test.mn_sat = df_test.mn_sat.str.replace((\",\"), (\"\"))\n",
        "df_test.income = df_test.income.str.replace((\",\"), (\"\"))\n",
        "\n",
        "# Convert to float\n",
        "df_train[[\"mn_sat\"]] = df_train[[\"mn_sat\"]].astype(float)\n",
        "df_train[[\"income\"]] = df_train[[\"income\"]].astype(float)\n",
        "\n",
        "df_test[[\"mn_sat\"]] = df_test[[\"mn_sat\"]].astype(float)\n",
        "df_test[[\"income\"]] = df_test[[\"income\"]].astype(float)\n",
        "\n",
        "# Fill the Missing Values with the mean\n",
        "df_train.mn_sat = df_train.mn_sat.fillna(df_train.mn_sat.mean())\n",
        "df_train.income = df_train.income.fillna(df_train.income.mean())\n",
        "\n",
        "df_test.mn_sat = df_test.mn_sat.fillna(df_test.mn_sat.mean())\n",
        "df_test.income = df_test.income.fillna(df_test.income.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKvmZKEAkL4L"
      },
      "outputs": [],
      "source": [
        "# Fill the Missing Values with the mode\n",
        "df_train['from'] = df_train['from'].fillna(df_train['from'].mode()[0])\n",
        "df_train['from'] = df_train['from'].str.upper()\n",
        "\n",
        "df_test['from'] = df_test['from'].fillna(df_test['from'].mode()[0])\n",
        "df_test['from'] = df_test['from'].str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c24RHl6xmtQV"
      },
      "outputs": [],
      "source": [
        "# Fill the Missing Values with the Constant\n",
        "df_train['field_cd'] = df_train['field_cd'].fillna(18)\n",
        "df_train['race'] = df_train['race'].fillna(6)\n",
        "df_train['race_o'] = df_train['race_o'].fillna(6)\n",
        "df_train['career_c'] = df_train['career_c'].fillna(15)\n",
        "df_train['field_cd'] = df_train['field_cd'].fillna(18)\n",
        "df_train['goal'] = df_train['goal'].fillna(6)\n",
        "\n",
        "\n",
        "df_test['field_cd'] = df_test['field_cd'].fillna(18)\n",
        "df_test['race'] = df_test['race'].fillna(6)\n",
        "df_test['race_o'] = df_test['race_o'].fillna(6)\n",
        "df_test['career_c'] = df_test['career_c'].fillna(15)\n",
        "df_test['field_cd'] = df_test['field_cd'].fillna(18)\n",
        "df_test['goal'] = df_test['goal'].fillna(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfuAtpDImtS8"
      },
      "outputs": [],
      "source": [
        "obj_tr=df_train.select_dtypes(include=['object']) \n",
        "obj_ts=df_test.select_dtypes(include=['object']) \n",
        "\n",
        "#categorical encoding of all object data\n",
        "for i in obj_tr:\n",
        "    df_train[i]=df_train[i].astype(\"category\")\n",
        "\n",
        "#categorical encoding of all object data\n",
        "for i in obj_ts:\n",
        "    df_test[i]=df_test[i].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EgOsh13mtVd"
      },
      "outputs": [],
      "source": [
        "X_train = df_train.drop(['match'], axis=1)\n",
        "y_train = df_train.match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN6mTkjGmtXj"
      },
      "outputs": [],
      "source": [
        "# RandomOverSampleris used for imbalanced data so the number of labels are equal.\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_train, y_train = ros.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eozX6E_cmtZx",
        "outputId": "f8d1172d-5f07-4091-9f8a-3a50485555d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Date Shape:  (9842, 190)\n",
            "Label Date Shape:  (9842,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Date Shape: \", X_train.shape)\n",
        "print(\"Label Date Shape: \", y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CN757UQ13uU"
      },
      "source": [
        "#Part 2: Building The Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Here I Will Do 6 Trials**,  \n",
        "\n",
        "### **Using 2 Models Which Are XGBoost And RandomForest.**\n",
        "\n",
        "\n",
        "\n",
        "**Each Model I Will Use RadomSearch, GridSearch And Finally BayesSearch, But What is The Difference Between those 3 Search Methodes ?**\n",
        "\n",
        "\n",
        "- **Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. It is similar to grid search, and yet it has proven to yield better results comparatively.**\n",
        "\n",
        "\n",
        "- **Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.**\n",
        "\n",
        "\n",
        "- **Bayesian optimization methods are efficient because they select hyperparameters in an informed manner. By prioritizing hyperparameters that appear more promising from past results, Bayesian methods can find the best hyperparameters in lesser time (in fewer iterations) than both grid search and random search.**\n",
        "\n"
      ],
      "metadata": {
        "id": "RT3qicr37pyx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ninz4tja18CZ"
      },
      "source": [
        "## A Tunable Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qd8FyUqttMb"
      },
      "outputs": [],
      "source": [
        "# Get Numeric features to featureNumeric\n",
        "featureNumeric = list(X_train.select_dtypes(include=['float64','int64']))\n",
        "\n",
        "# Get Categorical features to featuresCategorical\n",
        "featuresCategorical=list(X_train.select_dtypes(include=['category']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClFW_lMFttO0"
      },
      "outputs": [],
      "source": [
        "# Create a pipline for numerical features and select it's hyperparameters\n",
        "numeric = Pipeline(\n",
        "    steps=[\n",
        "           ('imputer', SimpleImputer(strategy='mean')), # SimpleImputer used to handel missing value and have strategy='mean' is default val that means fill nan value with mean\n",
        "           ('scaler', StandardScaler())  # StandardScaler used to scale number\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical=Pipeline(\n",
        "    steps=[\n",
        "           ('imputer',SimpleImputer(strategy='constant')), # SimpleImputer used to handel missing value and have strategy='constant' that means fill nan value with constant\n",
        "            ('onehot',OneHotEncoder(handle_unknown='ignore'))# OneHotEncoder used to encode categorical data\n",
        "    ]\n",
        ")\n",
        "# ColumnTransformer used to construct and apply separate numerical and categorical data transformers.\n",
        "# Select and prepare the columns of the dataset before fitting a model to the modified data.\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric, featureNumeric),# Numerical data\n",
        "        ('cat', categorical, featuresCategorical) # Categorical data\n",
        "    ]\n",
        ")\n",
        "# Put the preprocessing a siutable classifier.\n",
        "full_piplinex = Pipeline(  \n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor), \n",
        "        ('my_classifier', \n",
        "           XGBClassifier(), # XGBClassifier as a classifier.\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "full_piplinex\n",
        "\n",
        "full_pipliner = Pipeline(  \n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor), \n",
        "        ('my_classifier', \n",
        "           RandomForestClassifier(), # RandomForestClassifier as a classifier.\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "full_pipliner\n",
        "\n",
        "np.random.seed(0)  # used to make the random numbers predictable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR_NyTJQttRN",
        "outputId": "c1f54ef4-2f53-4522-95d1-51f44d11d471"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fitting and predict The pipeline object.\n",
        "full_piplinel = full_piplinex.fit(X_train, y_train)\n",
        "full_piplinel.predict(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVNFT_9Q2F4G"
      },
      "source": [
        "## XGBoost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost (eXtreme Gradient Boosting) is a popular supervised-learning algorithm used for regression and classification on large datasets. It uses sequentially-built shallow decision trees to provide accurate results and a highly-scalable training method that avoids overfitting.**\n",
        "\n",
        "**XGBoost consists of a number of hyper-parameters that can be tuned â€” a primary advantage over gradient boosting machines. XGBoost has an in-built capability to handle missing values. It provides various intuitive features, such as parallelisation, distributed computing, cache optimisation, and more.**\n",
        "\n"
      ],
      "metadata": {
        "id": "HJw60jOy7SeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MvM6wmlHttTd",
        "outputId": "ed1eb4d6-d79b-4592-a563-f47b07344ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc...\n",
              "                               feature_types=None, gamma=0, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=8, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=500,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters for RandomSearch for XGBoost\n",
        "xgb_param = {\n",
        "  'my_classifier__n_estimators': [450,500],\n",
        "  'my_classifier__max_depth': [8,10],\n",
        "  'my_classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "  'my_classifier__gamma': [0, 0.1, 0.2],\n",
        "  'my_classifier__subsample': [0.8, 0.9, 1]\n",
        "}\n",
        "# Create RandomizedSearch objects\n",
        "xgb_random = RandomizedSearchCV(full_piplinex, xgb_param, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1).fit(X_train, y_train)\n",
        "\n",
        "# Get best models\n",
        "xgb_random.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqH4ZZ5m1CPK",
        "outputId": "ba6e5410-912f-4e68-910e-48bfdf145b8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'my_classifier__subsample': 0.9,\n",
              " 'my_classifier__n_estimators': 500,\n",
              " 'my_classifier__max_depth': 8,\n",
              " 'my_classifier__learning_rate': 0.1,\n",
              " 'my_classifier__gamma': 0}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best parameters\n",
        "xgb_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsotefKC1CRh",
        "outputId": "3375eefa-d592-46d7-f7be-73e9e8688788"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9980082785506573"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best score\n",
        "xgb_random.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "5Kak_DzJ1OFg",
        "outputId": "aa918de2-c9f1-405e-a7ff-f7ea5c8667ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc...\n",
              "                               feature_types=None, gamma=0.0, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=10, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=450,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters for BayesSearch for XGBoost\n",
        "xgb_param_bayes = {\n",
        "  'my_classifier__n_estimators': Categorical([400,500]),\n",
        "  'my_classifier__max_depth': Integer(3,100),\n",
        "  'my_classifier__learning_rate':Real(1e-5, 0.2, prior='log-uniform'),\n",
        "  'my_classifier__gamma':Real(1e-5, 0.2, prior='log-uniform'),\n",
        "  'my_classifier__subsample':Real(0.5, 1, prior='log-uniform')\n",
        "}\n",
        "\n",
        "# Create Bayes object\n",
        "xgb_bayes = BayesSearchCV(full_piplinex, xgb_param,n_iter=20, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1).fit(X_train, y_train)\n",
        "\n",
        "# Get best models\n",
        "xgb_bayes.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWI4t3HX1fTh",
        "outputId": "4f7308c4-de10-4b95-dc02-62e7afc48fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('my_classifier__gamma', 0.0),\n",
              "             ('my_classifier__learning_rate', 0.1),\n",
              "             ('my_classifier__max_depth', 10),\n",
              "             ('my_classifier__n_estimators', 450),\n",
              "             ('my_classifier__subsample', 0.8)])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best parameters\n",
        "xgb_bayes.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5CgnCmN1fax",
        "outputId": "3148d1bb-1c45-41d8-ae63-6b4dd328f571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9983364601021737"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best score\n",
        "xgb_bayes.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw6GlMef47h7",
        "outputId": "38aa09f7-4550-410b-fd44-5f423c268199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc...\n",
              "                               feature_types=None, gamma=0, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=0.1,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=10, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=450,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters for Grid for XGBoost\n",
        "xgb_param_grid = {\n",
        "  'my_classifier__n_estimators': [450,500],\n",
        "  'my_classifier__max_depth': [8,10],\n",
        "  'my_classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "  'my_classifier__gamma': [0, 0.1, 0.2],\n",
        "  'my_classifier__subsample': [0.8, 0.9, 1]\n",
        "}\n",
        "\n",
        "xgb_grid = GridSearchCV(full_piplinex, xgb_param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1).fit(X_train, y_train)\n",
        "xgb_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qeSwXKL47lD",
        "outputId": "89d6c1a5-13dc-45a8-fd0e-7d3e90f5891f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'my_classifier__gamma': 0,\n",
              " 'my_classifier__learning_rate': 0.1,\n",
              " 'my_classifier__max_depth': 10,\n",
              " 'my_classifier__n_estimators': 450,\n",
              " 'my_classifier__subsample': 0.9}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4ZhXG6m47n4",
        "outputId": "02ce13f9-dbf6-4fd4-b9b0-31a1fdb659a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9984027339499593"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_grid.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyLuKSti2PBo"
      },
      "source": [
        "## RandomForest Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForest uses multiple decision trees to make predictions. It is useful for handling large data sets with many variables and reducing overfitting and variance. Some advantages of RandomForest Model are:**\n",
        "\n",
        "- **It can handle both classification and regression problems.**\n",
        "- **It can deal with missing values and outliers.**\n",
        "- **It can measure the importance of each feature.**"
      ],
      "metadata": {
        "id": "pPp4GV2v9q8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoLvQIhi1fdg",
        "outputId": "4f6b9034-fd78-4201-8db1-e796dbfbafd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc_o', 'intel_o', 'fun_o',\n",
              "                                                   'amb_o', 'shar_o', 'like_o',\n",
              "                                                   'prob_o', 'met_o', 'age', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['field', 'undergra',\n",
              "                                                   'tuition', 'from', 'zipcode',\n",
              "                                                   'career'])])),\n",
              "                ('my_classifier',\n",
              "                 RandomForestClassifier(criterion='entropy', max_depth=20,\n",
              "                                        n_estimators=450))])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters for RandomSearch for RandomForest\n",
        "rf_param = {\n",
        "    'my_classifier__n_estimators': [400,450],\n",
        "    'my_classifier__max_depth': [10,20],\n",
        "    'my_classifier__max_features': ['auto', 'sqrt'],\n",
        "    'my_classifier__criterion': ['entropy'],\n",
        "    'my_classifier__min_samples_split':[2,4]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Create RandomizedSearch object\n",
        "rf_random = RandomizedSearchCV(full_pipliner,rf_param, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc').fit(X_train, y_train)\n",
        "\n",
        "# Get best models\n",
        "rf_random.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO58acHn1ff4",
        "outputId": "87a822bc-e98d-4597-ada6-45a82e799892"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'my_classifier__n_estimators': 450,\n",
              " 'my_classifier__min_samples_split': 2,\n",
              " 'my_classifier__max_features': 'auto',\n",
              " 'my_classifier__max_depth': 20,\n",
              " 'my_classifier__criterion': 'entropy'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best parameters\n",
        "rf_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsQoX4og1fio",
        "outputId": "5e540a47-aa8e-48ac-b17f-3dde4768b352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9989147993080154"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best score\n",
        "rf_random.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6DX433C2vxB",
        "outputId": "69ef51ff-83d9-425f-ab81-66d8463daa06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc...\n",
              "                                                   'amb_o', 'shar_o', 'like_o',\n",
              "                                                   'prob_o', 'met_o', 'age', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['field', 'undergra',\n",
              "                                                   'tuition', 'from', 'zipcode',\n",
              "                                                   'career'])])),\n",
              "                ('my_classifier',\n",
              "                 RandomForestClassifier(criterion='entropy', max_depth=20,\n",
              "                                        max_features='sqrt',\n",
              "                                        n_estimators=450))])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters for BayesSearch for RandomForest\n",
        "rf_param_bayes = {\n",
        "    'my_classifier__n_estimators': Categorical([400, 500]),\n",
        "    'my_classifier__max_depth': Integer(3,100),\n",
        "    'my_classifier__max_features': Categorical(['auto', 'sqrt']),\n",
        "    'my_classifier__criterion': Categorical(['entropy']),\n",
        "    'my_classifier__min_samples_split':Integer(3,10)\n",
        "}\n",
        "# Create Bayes object\n",
        "rf_bayes = BayesSearchCV(full_pipliner,rf_param, cv=5, n_jobs=-1, verbose=1,n_iter=20, scoring='roc_auc').fit(X_train, y_train)\n",
        "\n",
        "# Get best models\n",
        "rf_bayes.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqLui7m22vzw",
        "outputId": "ab584956-0443-4c13-f9fd-d807e6f1c824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('my_classifier__criterion', 'entropy'),\n",
              "             ('my_classifier__max_depth', 20),\n",
              "             ('my_classifier__max_features', 'sqrt'),\n",
              "             ('my_classifier__min_samples_split', 2),\n",
              "             ('my_classifier__n_estimators', 450)])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best parameters\n",
        "rf_bayes.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFfbdnwO2v2h",
        "outputId": "b3b74812-6697-4a94-dbd6-83c8921aacd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9988710253830593"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get best score\n",
        "rf_bayes.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooFb8EEf3gt6",
        "outputId": "d5212225-5fb1-48c5-c593-df9bf80fa698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc...\n",
              "                                                   'amb_o', 'shar_o', 'like_o',\n",
              "                                                   'prob_o', 'met_o', 'age', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['field', 'undergra',\n",
              "                                                   'tuition', 'from', 'zipcode',\n",
              "                                                   'career'])])),\n",
              "                ('my_classifier',\n",
              "                 RandomForestClassifier(criterion='entropy', max_depth=20,\n",
              "                                        max_features='sqrt',\n",
              "                                        n_estimators=400))])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#create grid search objects\n",
        "rf_param_grid = {\n",
        "    'my_classifier__n_estimators': [400,450],\n",
        "    'my_classifier__max_depth': [10,20],\n",
        "    'my_classifier__max_features': ['auto', 'sqrt'],\n",
        "    'my_classifier__criterion': ['entropy'],\n",
        "    'my_classifier__min_samples_split':[2,4]\n",
        "}\n",
        "rf_grid = GridSearchCV(full_pipliner,rf_param_grid, cv=5, n_jobs=-1, verbose=1, scoring='roc_auc').fit(X_train, y_train)#get best models\n",
        "rf_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI-VkbU83gwZ",
        "outputId": "bb896d85-9af4-4a4e-da31-9c6ef7e3fd32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'my_classifier__criterion': 'entropy',\n",
              " 'my_classifier__max_depth': 20,\n",
              " 'my_classifier__max_features': 'sqrt',\n",
              " 'my_classifier__min_samples_split': 2,\n",
              " 'my_classifier__n_estimators': 400}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmW-gGpT3gy2",
        "outputId": "bb2b9800-4998-4714-d9ee-516daa1e4709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9989447118989887"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_grid.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V_OqjZD5Mfp"
      },
      "source": [
        "# Part 3: Trying the Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsxBZTYP6D9L"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pred_xgb_random = pd.DataFrame()\n",
        "\n",
        "Pred_xgb_random['id'] = df_test.index\n",
        "\n",
        "Pred_xgb_random['match'] = xgb_random.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_xgb_random.to_csv('xgb_random.csv', index=False)"
      ],
      "metadata": {
        "id": "GKcDvL7hF-mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z6HUbUq5T_I"
      },
      "outputs": [],
      "source": [
        "Pred_xgb_grid = pd.DataFrame()\n",
        "\n",
        "Pred_xgb_grid['id'] = df_test.index\n",
        "\n",
        "Pred_xgb_grid['match'] = xgb_grid.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_xgb_grid.to_csv('xgb_grid.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWmG57eiFzpr"
      },
      "outputs": [],
      "source": [
        "Pred_xgb_bayes = pd.DataFrame()\n",
        "\n",
        "Pred_xgb_bayes['id'] = df_test.index\n",
        "\n",
        "Pred_xgb_bayes['match'] = xgb_bayes.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_xgb_bayes.to_csv('xgb_bayes.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Pip84n6df5"
      },
      "source": [
        "## RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7SabqtO5Uda"
      },
      "outputs": [],
      "source": [
        "Pred_rf_grid = pd.DataFrame()\n",
        "\n",
        "Pred_rf_grid['id'] = df_test.index\n",
        "\n",
        "Pred_rf_grid['match'] = rf_grid.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_rf_grid.to_csv('rf_grid.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCGPMJDgFzps"
      },
      "outputs": [],
      "source": [
        "Pred_rf_random = pd.DataFrame()\n",
        "\n",
        "Pred_rf_random['id'] = df_test.index\n",
        "\n",
        "Pred_rf_random['match'] = rf_random.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_rf_random.to_csv('rf_random.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGTUusAWFzps"
      },
      "outputs": [],
      "source": [
        "Pred_rf_bayes = pd.DataFrame()\n",
        "\n",
        "Pred_rf_bayes['id'] = df_test.index\n",
        "\n",
        "Pred_rf_bayes['match'] = rf_bayes.predict_proba(df_test)[:,1]\n",
        "\n",
        "Pred_rf_bayes.to_csv('rf_bayes.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aMtR7uYWze49",
        "Hnm8UOnNGEb9",
        "IlxVAhaT13MO",
        "9QtJ0uOh5rie",
        "1CN757UQ13uU",
        "Ninz4tja18CZ",
        "bVNFT_9Q2F4G",
        "AyLuKSti2PBo",
        "4V_OqjZD5Mfp",
        "zsxBZTYP6D9L",
        "O-Pip84n6df5"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}